# Wine-Classification-using-Machine-Learning

ğŸ· Wine Classification using Machine Learning
ğŸ“Œ Project Overview

This project builds and compares multiple machine learning classification models on the Wine Dataset from the UCI Machine Learning Repository.

The dataset contains the results of chemical analysis of wines grown in the same region in Italy but derived from three different cultivars.

The goal is to classify wines into one of three categories based on 13 chemical features.

ğŸ“Š Dataset Information

ğŸ“ Source: Wine Dataset

ğŸ§¾ Total Samples: 178

ğŸ¯ Target Classes: 3 (Wine types)

ğŸ”¢ Features: 13 continuous numerical variables

ğŸ“Œ First column: Class label (1â€“3)

Features:

Alcohol

Malic Acid

Ash

Alcalinity of Ash

Magnesium

Total Phenols

Flavanoids

Nonflavanoid Phenols

Proanthocyanins

Color Intensity

Hue

OD280/OD315

Proline

All features are continuous.

âš™ï¸ Data Preprocessing

Converted class labels from (1,2,3) â†’ (0,1,2) using LabelEncoder

Train-Test split (80% â€“ 20%)

Stratified sampling to maintain class balance

StandardScaler applied for scale-sensitive models

ğŸ¤– Models Implemented

The following classifiers were trained and evaluated:

Logistic Regression

Support Vector Machine (SVM)

K-Nearest Neighbors (KNN)

Random Forest

XGBoost

Cross-validation (5-fold) was used for robust evaluation.

ğŸ“ˆ Model Performance
Model	Test Accuracy	CV Accuracy
Logistic Regression	~97â€“100%	~97%+
SVM	~98â€“100%	~98%+
KNN	~95â€“98%	~96%+
Random Forest	~99%	~98%+
XGBoost	ğŸ”¥ ~99â€“100%	~99%

The dataset has well-separated classes, making it suitable for benchmarking new classifiers.



XGBoost and Random Forest achieved the highest accuracy.

XGBoost was configured for multi-class classification using:

objective = "multi:softprob"
eval_metric = "mlogloss"

ğŸ§  Key Learnings

Importance of feature scaling for distance-based models

Stratified sampling improves evaluation reliability

Ensemble models perform exceptionally well on structured tabular data

Proper label encoding is required for certain models like XGBoost

ğŸ“‚ Project Structure
Wine-Classification/
â”‚
â”œâ”€â”€ Wine dataset.csv
â”œâ”€â”€ wine_classification.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ›  Technologies Used

Python

Pandas

NumPy

Scikit-learn

XGBoost

Matplotlib (optional for visualization)

ğŸš€ Future Improvements

Hyperparameter tuning with GridSearchCV

Feature importance visualization

SHAP model explainability

PCA dimensionality reduction

Deployment using Flask / FastAPI

ğŸ“Œ Author

Jagruti Yuvraj Dhangar
Machine Learning | Data Science | AI Enthusiast

toget code with dataset----------------------
kaggle link =https://www.kaggle.com/code/jagrutiyuvrajdhangar/wine-classification-using-machine-learning/edit  
